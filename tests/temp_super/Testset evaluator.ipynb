{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                 constants for the evaluators\n",
    "#######################################################\n",
    "\n",
    "MIN_MEASUREMENT_NUMBER = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False, 'test_num': 2, 'base_path': 'mprtp2', 'channel': '1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Subflow</th>\n",
       "      <th>2 Subflows</th>\n",
       "      <th>3 Subflows</th>\n",
       "      <th>5 Subflows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>406 ± 16</td>\n",
       "      <td>671 ± 32</td>\n",
       "      <td>967 ± 46</td>\n",
       "      <td>1627 ± 102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABU [%]</th>\n",
       "      <td>78% ± 2%</td>\n",
       "      <td>66% ± 2%</td>\n",
       "      <td>64% ± 1%</td>\n",
       "      <td>64% ± 3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>1% ± 0%</td>\n",
       "      <td>1% ± 0%</td>\n",
       "      <td>1% ± 0%</td>\n",
       "      <td>2% ± 1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>114.23 ± 1.78</td>\n",
       "      <td>104.8 ± 0.76</td>\n",
       "      <td>104.24 ± 0.39</td>\n",
       "      <td>103.89 ± 0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1 Subflow    2 Subflows     3 Subflows     5 Subflows\n",
       "GP [kbps]       406 ± 16      671 ± 32       967 ± 46     1627 ± 102\n",
       "ABU [%]         78% ± 2%      66% ± 2%       64% ± 1%       64% ± 3%\n",
       "LR [%]           1% ± 0%       1% ± 0%        1% ± 0%        2% ± 1%\n",
       "QMD [ms]   114.23 ± 1.78  104.8 ± 0.76  104.24 ± 0.39  103.89 ± 0.92"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#                 in-phase evaluator - mprtp2\n",
    "#######################################################\n",
    "\n",
    "# mprtp 2 - equal RTT, changing bw\n",
    "# mprtp 8 - equal RTT, equal bw\n",
    "# mprtp 9 - different RTT, equal bw\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "packets_colnames = [\"Tracked NTP\",\n",
    "                    \"Sequence Number\",\n",
    "                    \"Timestamp\",\n",
    "                    \"SSRC\",\n",
    "                    \"Payload Type\",\n",
    "                    \"Payload Size\",\n",
    "                    \"Subflow ID\",\n",
    "                    \"Subflow Sequence Number\",\n",
    "                    \"Header Size\",\n",
    "                    \"Protect Begin\",\n",
    "                    \"Protect End\",\n",
    "                    \"Marker\",\n",
    "                   ]\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, channel, path, subflow_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        sr = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'subflow_'+ str(subflow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "        \n",
    "    \n",
    "def collect_subflows(channel, path, subflows_num):\n",
    "    subflows = [Subflow(channel, path, subflow_id) for subflow_id in range(1, subflows_num + 1)]\n",
    "    return subflows\n",
    "\n",
    "    \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "configs = [\n",
    "{\n",
    "    'base_path': \"mprtp2\", \"test_num\": 2,\n",
    "#     'base_path': \"mprtp8\", \"test_num\": 8\n",
    "    'debug': False,\n",
    "#     'debug': True,\n",
    "    'channel': \"1\"\n",
    "},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    for path,dirs,files in os.walk(config['base_path']):\n",
    "        if len(dirs) < 1:\n",
    "            continue\n",
    "        final_table = pd.DataFrame()\n",
    "    #     for subflows_num in [5]:\n",
    "        for subflows_num in [1, 2, 3, 5]:\n",
    "    #         print(\"number of subflows\", subflows_num)\n",
    "            suffix = \"_\" + str(subflows_num)\n",
    "            metrics = {\n",
    "                'SR': [],\n",
    "                'ABU': [],\n",
    "                'LR': [],\n",
    "                'LRN': [],            \n",
    "                'QMD': [],\n",
    "                'GP': [],\n",
    "            }\n",
    "            subjects = []\n",
    "            for directory in dirs:\n",
    "                if not directory.endswith(suffix):\n",
    "                    continue\n",
    "                try:\n",
    "                    subflows = collect_subflows(config['channel'], config['base_path'] + '/' + directory, subflows_num)\n",
    "                except:\n",
    "                    print(\"There is an exception occured at:\", directory)\n",
    "                \n",
    "                abs_ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows)\n",
    "                abs_LR = sum(subflow.get_summary()['LR'] for subflow in subflows)\n",
    "                abs_GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "                abs_QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows)\n",
    "                abs_LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)\n",
    "                subjects.append((directory, abs_ABU, abs_LR, abs_GP, abs_QMD, abs_LRN))\n",
    "                \n",
    "                SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "                ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) / float(subflows_num)\n",
    "                LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "                LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "                QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "                GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "                metrics['SR'].append(SR)\n",
    "                metrics['ABU'].append(ABU)            \n",
    "                metrics['LR'].append(LR)\n",
    "                metrics['LRN'].append(LRN)            \n",
    "                metrics['QMD'].append(QMD)\n",
    "                metrics['GP'].append(GP)\n",
    "\n",
    "            # Selection method\n",
    "            # setup sets for the max 10 based on criteria (LR, ABU, and verifications) and filter out the \n",
    "            # intersection of the weakers\n",
    "\n",
    "            # Display parameters\n",
    "            if config['debug']:\n",
    "                index = 1\n",
    "                if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                    print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                          it does not have the necessary minimum number of measurements\")\n",
    "    #             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "                sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "                for item in sorted_list:\n",
    "                    print(\"Rank:\", index)\n",
    "                    print(\"Directory, ABU, LR, GP, QMD, LRN: \", item)\n",
    "                    pdf = PDF(config['base_path'] + '/' + item[0] + '/' + 'mprtp' + config['test_num'] \n",
    "                              + '_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                    display(pdf)\n",
    "                    index += 1\n",
    "                print('-' * 20)\n",
    "\n",
    "            subflow_col = (str(subflows_num) + ' Subflows') if 1 < subflows_num else '1 Subflow'\n",
    "            final_table[subflow_col] = list(range(7))\n",
    "            SRs = np.asarray(metrics['SR'])\n",
    "            ABUs = np.asarray(metrics['ABU'])\n",
    "            LRs = np.asarray(metrics['LR'])\n",
    "            LRNs = np.asarray(metrics['LRN'])\n",
    "            QMDs = np.asarray(metrics['QMD'])\n",
    "            GPs = np.asarray(metrics['GP'])\n",
    "            \n",
    "            try:\n",
    "                final_table[subflow_col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "                final_table[subflow_col][1] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "                final_table[subflow_col][2] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "                final_table[subflow_col][3] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "                final_table[subflow_col][4] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "                final_table[subflow_col][5] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "                final_table[subflow_col][6] = str(len(metrics['SR']))\n",
    "            except:\n",
    "                print(\"Problem in final table\", directory)\n",
    "\n",
    "        final_table = final_table.rename({\n",
    "            0: 'GP [kbps]',\n",
    "            1: 'ABU [%]', \n",
    "            2: 'LR [%]', \n",
    "            3: 'LRN',\n",
    "            4: 'QMD [ms]',\n",
    "            5: 'SR [kbps]',\n",
    "            6: 'Samples'}, axis='index')\n",
    "    #     display(final_table)\n",
    "        display(final_table.loc[['GP [kbps]', 'ABU [%]', 'LR [%]', 'QMD [ms]'], :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:173: RuntimeWarning: Mean of empty slice.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5fc0d6795f62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mTEs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfinal_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubflow_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ± '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGPs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mfinal_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubflow_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mABUs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'% ± '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mABUs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfinal_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubflow_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLRs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'% ± '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLRs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "#######################################################\n",
    "#                 out-of-phase evaluator - mprtp4\n",
    "#######################################################\n",
    "\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def extract_dataframe(filename, identifier):\n",
    "    header = False\n",
    "    content = []\n",
    "    identifier_length = len(identifier)\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if identifier not in line:\n",
    "                continue\n",
    "            stat_line = line[identifier_length:]\n",
    "            if \"Subflow ID\" in stat_line:\n",
    "                if header is True:\n",
    "                    continue\n",
    "                header = True\n",
    "            content.append(stat_line)\n",
    "    if len(content) < 1:\n",
    "        return None\n",
    "    TESTDATA = StringIO('\\n'.join(map(unicode,content)))\n",
    "    return pd.read_csv(TESTDATA)\n",
    "\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, path, stats_df, subflow_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._stat = stats_df[stats_df[\"Subflow ID\"] == subflow_id]\n",
    "\n",
    "        sr = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'subflow_'+ str(subflow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_1_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_1_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp,\n",
    "            'TE': self._stat[\"Target Error\"].mean()\n",
    "        }\n",
    "\n",
    "# The variance around the target is not significantly higher than in case of one subflow\n",
    "# the ratio stability\n",
    "\n",
    "base_path = \"mprtp4\"\n",
    "debug = False\n",
    "# debug = True\n",
    "for path,dirs,files in os.walk(base_path):\n",
    "    if len(dirs) < 1:\n",
    "        continue\n",
    "    final_table = pd.DataFrame()\n",
    "#     for subflows_num in [1]:\n",
    "    for subflows_num in [1, 2]:\n",
    "        suffix = \"_\" + str(subflows_num)\n",
    "        metrics = {\n",
    "            'SR': [],\n",
    "            'ABU': [],\n",
    "            'LR': [],\n",
    "            'LRN': [],            \n",
    "            'QMD': [],\n",
    "            'GP': [],\n",
    "            'TE': [],\n",
    "        }\n",
    "        subjects = []\n",
    "        for directory in dirs:\n",
    "            if not directory.endswith(suffix):\n",
    "                continue\n",
    "            filename = os.path.join(base_path, directory, \"mprtpflow_4_\" + str(subflows_num) + \"-snd.log\")\n",
    "            stats_df = extract_dataframe(filename, \"Stat:\")\n",
    "            stats_df[\"Target Error\"] = (stats_df[\"Target Rate [kbps]\"] - stats_df[\"Sending Rate [kbps]\"]) / stats_df[\"Target Rate [kbps]\"]\n",
    "            subflows = []\n",
    "            for subflow_id in range(1, subflows_num + 1):\n",
    "                subflows.append(Subflow(os.path.join(base_path, directory), stats_df, subflow_id))\n",
    "            \n",
    "            abs_ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows)\n",
    "            abs_LR = sum(subflow.get_summary()['LR'] for subflow in subflows)\n",
    "            abs_GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "            abs_QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows)\n",
    "            abs_TE = sum(subflow.get_summary()['TE'] for subflow in subflows)\n",
    "            subjects.append((directory, abs_ABU, abs_LR, abs_GP, abs_QMD, abs_TE))\n",
    "            \n",
    "            SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "            ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) / float(subflows_num)\n",
    "            LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "            LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "            QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "            GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "            TE = sum(subflow.get_summary()['TE'] for subflow in subflows) / float(subflows_num)            \n",
    "            metrics['SR'].append(SR)\n",
    "            metrics['ABU'].append(ABU)            \n",
    "            metrics['LR'].append(LR)\n",
    "            metrics['LRN'].append(LRN)            \n",
    "            metrics['QMD'].append(QMD)\n",
    "            metrics['GP'].append(GP)\n",
    "            metrics['TE'].append(TE)\n",
    "        \n",
    "        # Display parameters\n",
    "        if debug:\n",
    "            index = 1\n",
    "            if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                      it does not have the necessary minimum number of measurements\")\n",
    "#             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "            sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "            for item in sorted_list:\n",
    "                print(\"Rank:\", index)\n",
    "                print(\"Directory, ABU, LR, GP, QMD, TE: \", item)\n",
    "                pdf = PDF(base_path + '/' + item[0] + '/' + 'mprtp4_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                display(pdf)\n",
    "                index += 1\n",
    "            print('-' * 20)\n",
    "            \n",
    "        subflow_col = (str(subflows_num) + ' Subflows') if 1 < subflows_num else '1 Subflow'\n",
    "        final_table[subflow_col] = list(range(7))\n",
    "        SRs = np.asarray(metrics['SR'])\n",
    "        ABUs = np.asarray(metrics['ABU'])\n",
    "        LRs = np.asarray(metrics['LR'])\n",
    "        LRNs = np.asarray(metrics['LRN'])\n",
    "        QMDs = np.asarray(metrics['QMD'])\n",
    "        GPs = np.asarray(metrics['GP'])\n",
    "        TEs = np.asarray(metrics['TE'])\n",
    "\n",
    "        final_table[subflow_col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "        final_table[subflow_col][1] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "        final_table[subflow_col][2] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "        final_table[subflow_col][3] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "        final_table[subflow_col][4] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "        final_table[subflow_col][5] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "        final_table[subflow_col][6] = str(int(TEs.mean() * 100)) + '% ± ' + str(int(TEs.std() * 100) ) + '%'\n",
    "        final_table[subflow_col][7] = str(len(metrics['SR']))\n",
    "        \n",
    "    final_table = final_table.rename({\n",
    "        0: 'GP [kbps]',\n",
    "        1: 'ABU [%]', \n",
    "        2: 'LR [%]', \n",
    "        3: 'LRN',\n",
    "        4: 'QMD [ms]',\n",
    "        5: 'SR [kbps]',\n",
    "        6: 'TE [%]',\n",
    "        7: 'Samples'}, axis='index')\n",
    "#     display(final_table)\n",
    "    display(final_table.loc[['GP [kbps]', 'TE [%]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False, 'mp_channel': '2', 'single_channel': '1', 'base_path': 'mprtp6'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:241: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:242: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:243: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:244: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:246: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:248: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTP flow</th>\n",
       "      <th>MPRTP flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>1037 ± 130</td>\n",
       "      <td>1796 ± 52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABU [%]</th>\n",
       "      <td>59% ± 6%</td>\n",
       "      <td>103% ± 2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>0% ± 0%</td>\n",
       "      <td>0% ± 0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>102.68 ± 1.66</td>\n",
       "      <td>101.87 ± 1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                RTP flow     MPRTP flow\n",
       "GP [kbps]     1037 ± 130      1796 ± 52\n",
       "ABU [%]         59% ± 6%      103% ± 2%\n",
       "LR [%]           0% ± 0%        0% ± 0%\n",
       "QMD [ms]   102.68 ± 1.66  101.87 ± 1.23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#      shared bottleneck, fairness test - mprtp5\n",
    "#######################################################\n",
    "# TODO!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "packets_colnames = [\"Tracked NTP\",\n",
    "                    \"Sequence Number\",\n",
    "                    \"Timestamp\",\n",
    "                    \"SSRC\",\n",
    "                    \"Payload Type\",\n",
    "                    \"Payload Size\",\n",
    "                    \"Subflow ID\",\n",
    "                    \"Subflow Sequence Number\",\n",
    "                    \"Header Size\",\n",
    "                    \"Protect Begin\",\n",
    "                    \"Protect End\",\n",
    "                    \"Marker\",\n",
    "                   ]\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, channel, path, subflow_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        sr = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'subflow_'+ str(subflow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "        \n",
    "\n",
    "class SingleFlow:\n",
    "    def __init__(self, channel, path, flow_id):\n",
    "        self._path = path\n",
    "        self._flow_id = flow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        sr = os.path.join(path, 'flow_'+ str(flow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'flows_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'flow_'+ str(flow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'flow_'+ str(flow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "        \n",
    "def collect_subflows(channel, path, subflows_num):\n",
    "    subflows = [Subflow(channel, path, subflow_id) for subflow_id in range(1, subflows_num + 1)]\n",
    "    return subflows\n",
    "\n",
    "    \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "configs = [\n",
    "{\n",
    "    'base_path': \"mprtp6\",\n",
    "    'debug': False,\n",
    "#     'debug': True,\n",
    "    'mp_channel': \"2\",\n",
    "    'single_channel': \"1\",\n",
    "}, \n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    for path,dirs,files in os.walk(config['base_path']):\n",
    "        if len(dirs) < 1:\n",
    "            continue\n",
    "        final_table = pd.DataFrame()\n",
    "    #         print(\"number of subflows\", subflows_num)\n",
    "        suffix = \"_\" + str(subflows_num)\n",
    "        metrics = {\n",
    "            'SR': [],\n",
    "            'ABU': [],\n",
    "            'LR': [],\n",
    "            'LRN': [],            \n",
    "            'QMD': [],\n",
    "            'GP': [],\n",
    "            \n",
    "            'single_SR': [],\n",
    "            'single_ABU': [],\n",
    "            'single_LR': [],\n",
    "            'single_LRN': [],            \n",
    "            'single_QMD': [],\n",
    "            'single_GP': [],\n",
    "        }\n",
    "\n",
    "        subjects = []\n",
    "        for directory in dirs:\n",
    "            subflows_num = 2\n",
    "            if not directory.endswith(suffix):\n",
    "                continue\n",
    "            try:\n",
    "                subflows = collect_subflows(config['mp_channel'], config['base_path'] + '/' + directory, subflows_num)\n",
    "            except:\n",
    "                print(\"There is an exception occured at:\", directory)\n",
    "\n",
    "            single_flow = SingleFlow(config['single_channel'], config['base_path'] + '/' + directory, 1)\n",
    "\n",
    "            abs_ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows)\n",
    "            abs_LR = sum(subflow.get_summary()['LR'] for subflow in subflows)\n",
    "            abs_GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "            abs_QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows)\n",
    "            abs_LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)\n",
    "            subjects.append((directory, abs_ABU, abs_LR, abs_GP, abs_QMD, abs_LRN))\n",
    "\n",
    "            SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "            ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) \n",
    "            LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "            LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "            QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "            GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "\n",
    "            metrics['SR'].append(SR)\n",
    "            metrics['ABU'].append(ABU)            \n",
    "            metrics['LR'].append(LR)\n",
    "            metrics['LRN'].append(LRN)            \n",
    "            metrics['QMD'].append(QMD)\n",
    "            metrics['GP'].append(GP)\n",
    "            \n",
    "            metrics['single_SR'].append(single_flow.get_summary()['SR'])\n",
    "            metrics['single_ABU'].append(single_flow.get_summary()['ABU'])            \n",
    "            metrics['single_LR'].append(single_flow.get_summary()['LR'])\n",
    "            metrics['single_LRN'].append(single_flow.get_summary()['LRN'])            \n",
    "            metrics['single_QMD'].append(single_flow.get_summary()['QMD'])\n",
    "            metrics['single_GP'].append(single_flow.get_summary()['GP'])\n",
    "\n",
    "        # Display parameters\n",
    "        if config['debug']:\n",
    "            index = 1\n",
    "            if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                      it does not have the necessary minimum number of measurements\")\n",
    "#             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "            sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "            for item in sorted_list:\n",
    "                print(\"Rank:\", index)\n",
    "                print(\"Directory, ABU, LR, GP, QMD, LRN: \", item)\n",
    "                pdf = PDF(config['base_path'] + '/' + item[0] + '/' + config['base_path'] + '_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                display(pdf)\n",
    "                index += 1\n",
    "            print('-' * 20)\n",
    "\n",
    "        final_table[\"RTP flow\"] = list(range(7))\n",
    "        final_table[\"MPRTP flow\"] = list(range(7))\n",
    "        SRs = np.asarray(metrics['SR'])\n",
    "        ABUs = np.asarray(metrics['ABU'])\n",
    "        LRs = np.asarray(metrics['LR'])\n",
    "        LRNs = np.asarray(metrics['LRN'])\n",
    "        QMDs = np.asarray(metrics['QMD'])\n",
    "        GPs = np.asarray(metrics['GP'])\n",
    "        \n",
    "        single_SRs = np.asarray(metrics['single_SR'])\n",
    "        single_ABUs = np.asarray(metrics['single_ABU'])\n",
    "        single_LRs = np.asarray(metrics['single_LR'])\n",
    "        single_LRNs = np.asarray(metrics['single_LRN'])\n",
    "        single_QMDs = np.asarray(metrics['single_QMD'])\n",
    "        single_GPs = np.asarray(metrics['single_GP'])\n",
    "\n",
    "        try:\n",
    "            col = \"RTP flow\"\n",
    "            final_table[col][0] = str(int(single_GPs.mean())) + ' ± ' + str(int(single_GPs.std()))\n",
    "            final_table[col][1] = str(int(single_ABUs.mean() * 100)) + '% ± ' + str(int(single_ABUs.std() * 100) ) + '%'\n",
    "            final_table[col][2] = str(int(single_LRs.mean() * 100) ) + '% ± ' + str(int(single_LRs.std() * 100)) + '%'\n",
    "            final_table[col][3] = str(int(single_LRNs.mean())) + ' ± ' + str(int(single_LRNs.std()))        \n",
    "            final_table[col][4] = str(round(single_QMDs.mean(), 2)) + ' ± ' + str(round(single_QMDs.std(), 2))\n",
    "            final_table[col][5] = str(int(single_SRs.mean())) + ' ± ' + str(int(single_SRs.std()) )\n",
    "            final_table[col][6] = str(len(metrics['single_SR']))\n",
    "            col = \"MPRTP flow\"\n",
    "            final_table[col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "            final_table[col][1] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "            final_table[col][2] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "            final_table[col][3] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "            final_table[col][4] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "            final_table[col][5] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "            final_table[col][6] = str(len(metrics['SR']))\n",
    "        except:\n",
    "            print(\"Problem in calculations\", directory)\n",
    "\n",
    "        final_table = final_table.rename({\n",
    "            0: 'GP [kbps]',\n",
    "            1: 'ABU [%]', \n",
    "            2: 'LR [%]', \n",
    "            3: 'LRN',\n",
    "            4: 'QMD [ms]',\n",
    "            5: 'SR [kbps]',\n",
    "            6: 'Samples'}, axis='index')\n",
    "    #     display(final_table)\n",
    "        display(final_table.loc[['GP [kbps]', 'ABU [%]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n",
    "    \n",
    "# We need the number of lost packets instead!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False, 'mp_channel': '2', 'single_channel_1': '1', 'base_path': 'mprtp7', 'single_channel_2': '3'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:265: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:266: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:268: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:269: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:270: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:272: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:276: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:277: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:280: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RTP flow 1</th>\n",
       "      <th>RTP flow 2</th>\n",
       "      <th>MPRTP flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>930 ± 234</td>\n",
       "      <td>956 ± 229</td>\n",
       "      <td>793 ± 189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>0% ± 0%</td>\n",
       "      <td>0% ± 0%</td>\n",
       "      <td>8% ± 26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>104.43 ± 3.76</td>\n",
       "      <td>103.95 ± 3.73</td>\n",
       "      <td>102.53 ± 2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              RTP flow 1     RTP flow 2     MPRTP flow\n",
       "GP [kbps]      930 ± 234      956 ± 229      793 ± 189\n",
       "LR [%]           0% ± 0%        0% ± 0%       8% ± 26%\n",
       "QMD [ms]   104.43 ± 3.76  103.95 ± 3.73  102.53 ± 2.62"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#      shared bottleneck, fairness test - mprtp7\n",
    "#######################################################\n",
    "# TODO!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "packets_colnames = [\"Tracked NTP\",\n",
    "                    \"Sequence Number\",\n",
    "                    \"Timestamp\",\n",
    "                    \"SSRC\",\n",
    "                    \"Payload Type\",\n",
    "                    \"Payload Size\",\n",
    "                    \"Subflow ID\",\n",
    "                    \"Subflow Sequence Number\",\n",
    "                    \"Header Size\",\n",
    "                    \"Protect Begin\",\n",
    "                    \"Protect End\",\n",
    "                    \"Marker\",\n",
    "                   ]\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, channel, path, subflow_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        sr = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'subflow_'+ str(subflow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "   \n",
    "\n",
    "class SingleFlow:\n",
    "    def __init__(self, channel, path, flow_id):\n",
    "        self._path = path\n",
    "        self._flow_id = flow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        sr = os.path.join(path, 'flow_'+ str(flow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'flows_'+ str(flow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'flow_'+ str(flow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'flow_'+ str(flow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "        \n",
    "def collect_subflows(channel, path, subflows_num):\n",
    "    subflows = [Subflow(channel, path, subflow_id) for subflow_id in range(1, subflows_num + 1)]\n",
    "    return subflows\n",
    "\n",
    "    \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "configs = [\n",
    "{\n",
    "    'base_path': \"mprtp7\",\n",
    "    'debug': False,\n",
    "#     'debug': True,\n",
    "    'mp_channel': \"2\",\n",
    "    'single_channel_1': \"1\",\n",
    "    'single_channel_2': \"3\",\n",
    "}, \n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    for path,dirs,files in os.walk(config['base_path']):\n",
    "        if len(dirs) < 1:\n",
    "            continue\n",
    "        final_table = pd.DataFrame()\n",
    "    #         print(\"number of subflows\", subflows_num)\n",
    "        suffix = \"_\" + str(subflows_num)\n",
    "        metrics = {\n",
    "            'SR': [],\n",
    "            'ABU': [],\n",
    "            'LR': [],\n",
    "            'LRN': [],            \n",
    "            'QMD': [],\n",
    "            'GP': [],\n",
    "            \n",
    "            'single_1_SR': [],\n",
    "            'single_1_ABU': [],\n",
    "            'single_1_LR': [],\n",
    "            'single_1_LRN': [],            \n",
    "            'single_1_QMD': [],\n",
    "            'single_1_GP': [],\n",
    "            \n",
    "            'single_2_SR': [],\n",
    "            'single_2_ABU': [],\n",
    "            'single_2_LR': [],\n",
    "            'single_2_LRN': [],            \n",
    "            'single_2_QMD': [],\n",
    "            'single_2_GP': [],\n",
    "        }\n",
    "\n",
    "        subjects = []\n",
    "        for directory in dirs:\n",
    "            subflows_num = 2\n",
    "            if not directory.endswith(suffix):\n",
    "                continue\n",
    "            try:\n",
    "                subflows = collect_subflows(config['mp_channel'], config['base_path'] + '/' + directory, subflows_num)\n",
    "            except:\n",
    "                print(\"There is an exception occured at:\", directory)\n",
    "\n",
    "            single_flow_1 = SingleFlow(config['single_channel_1'], config['base_path'] + '/' + directory, 1)\n",
    "            single_flow_2 = SingleFlow(config['single_channel_2'], config['base_path'] + '/' + directory, 2)\n",
    "\n",
    "            abs_ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows)\n",
    "            abs_LR = sum(subflow.get_summary()['LR'] for subflow in subflows)\n",
    "            abs_GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "            abs_QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows)\n",
    "            abs_LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)\n",
    "            subjects.append((directory, abs_ABU, abs_LR, abs_GP, abs_QMD, abs_LRN))\n",
    "\n",
    "            SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "            ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) \n",
    "            LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "            LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "            QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "            GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "\n",
    "            metrics['SR'].append(SR)\n",
    "            metrics['ABU'].append(ABU)            \n",
    "            metrics['LR'].append(LR)\n",
    "            metrics['LRN'].append(LRN)            \n",
    "            metrics['QMD'].append(QMD)\n",
    "            metrics['GP'].append(GP)\n",
    "            \n",
    "            metrics['single_1_SR'].append(single_flow_1.get_summary()['SR'])\n",
    "            metrics['single_1_ABU'].append(single_flow_1.get_summary()['ABU'])            \n",
    "            metrics['single_1_LR'].append(single_flow_1.get_summary()['LR'])\n",
    "            metrics['single_1_LRN'].append(single_flow_1.get_summary()['LRN'])            \n",
    "            metrics['single_1_QMD'].append(single_flow_1.get_summary()['QMD'])\n",
    "            metrics['single_1_GP'].append(single_flow_1.get_summary()['GP'])\n",
    "            \n",
    "            metrics['single_2_SR'].append(single_flow_2.get_summary()['SR'])\n",
    "            metrics['single_2_ABU'].append(single_flow_2.get_summary()['ABU'])            \n",
    "            metrics['single_2_LR'].append(single_flow_2.get_summary()['LR'])\n",
    "            metrics['single_2_LRN'].append(single_flow_2.get_summary()['LRN'])            \n",
    "            metrics['single_2_QMD'].append(single_flow_2.get_summary()['QMD'])\n",
    "            metrics['single_2_GP'].append(single_flow_2.get_summary()['GP'])\n",
    "\n",
    "        # Display parameters\n",
    "        if config['debug']:\n",
    "            index = 1\n",
    "            if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                      it does not have the necessary minimum number of measurements\")\n",
    "#             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "            sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "            for item in sorted_list:\n",
    "                print(\"Rank:\", index)\n",
    "                print(\"Directory, ABU, LR, GP, QMD, LRN: \", item)\n",
    "                pdf = PDF(config['base_path'] + '/' + item[0] + '/' + config['base_path'] + '_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                display(pdf)\n",
    "                index += 1\n",
    "            print('-' * 20)\n",
    "\n",
    "        final_table[\"RTP flow 1\"] = list(range(7))\n",
    "        final_table[\"RTP flow 2\"] = list(range(7))        \n",
    "        final_table[\"MPRTP flow\"] = list(range(7))\n",
    "        SRs = np.asarray(metrics['SR'])\n",
    "        ABUs = np.asarray(metrics['ABU'])\n",
    "        LRs = np.asarray(metrics['LR'])\n",
    "        LRNs = np.asarray(metrics['LRN'])\n",
    "        QMDs = np.asarray(metrics['QMD'])\n",
    "        GPs = np.asarray(metrics['GP'])\n",
    "        \n",
    "        single_1_SRs = np.asarray(metrics['single_1_SR'])\n",
    "        single_1_ABUs = np.asarray(metrics['single_1_ABU'])\n",
    "        single_1_LRs = np.asarray(metrics['single_1_LR'])\n",
    "        single_1_LRNs = np.asarray(metrics['single_1_LRN'])\n",
    "        single_1_QMDs = np.asarray(metrics['single_1_QMD'])\n",
    "        single_1_GPs = np.asarray(metrics['single_1_GP'])\n",
    "        \n",
    "        single_2_SRs = np.asarray(metrics['single_2_SR'])\n",
    "        single_2_ABUs = np.asarray(metrics['single_2_ABU'])\n",
    "        single_2_LRs = np.asarray(metrics['single_2_LR'])\n",
    "        single_2_LRNs = np.asarray(metrics['single_2_LRN'])\n",
    "        single_2_QMDs = np.asarray(metrics['single_2_QMD'])\n",
    "        single_2_GPs = np.asarray(metrics['single_2_GP'])\n",
    "\n",
    "        try:\n",
    "            col = \"RTP flow 1\"\n",
    "            final_table[col][0] = str(int(single_1_GPs.mean())) + ' ± ' + str(int(single_1_GPs.std()))\n",
    "            final_table[col][1] = str(int(single_1_ABUs.mean() * 100)) + '% ± ' + str(int(single_1_ABUs.std() * 100) ) + '%'\n",
    "            final_table[col][2] = str(int(single_1_LRs.mean() * 100) ) + '% ± ' + str(int(single_1_LRs.std() * 100)) + '%'\n",
    "            final_table[col][3] = str(int(single_1_LRNs.mean())) + ' ± ' + str(int(single_1_LRNs.std()))        \n",
    "            final_table[col][4] = str(round(single_1_QMDs.mean(), 2)) + ' ± ' + str(round(single_1_QMDs.std(), 2))\n",
    "            final_table[col][5] = str(int(single_1_SRs.mean())) + ' ± ' + str(int(single_1_SRs.std()) )\n",
    "            final_table[col][6] = str(len(metrics['single_1_SR']))\n",
    "            col = \"RTP flow 2\"\n",
    "            final_table[col][0] = str(int(single_2_GPs.mean())) + ' ± ' + str(int(single_2_GPs.std()))\n",
    "            final_table[col][1] = str(int(single_2_ABUs.mean() * 100)) + '% ± ' + str(int(single_2_ABUs.std() * 100) ) + '%'\n",
    "            final_table[col][2] = str(int(single_2_LRs.mean() * 100) ) + '% ± ' + str(int(single_2_LRs.std() * 100)) + '%'\n",
    "            final_table[col][3] = str(int(single_2_LRNs.mean())) + ' ± ' + str(int(single_2_LRNs.std()))        \n",
    "            final_table[col][4] = str(round(single_2_QMDs.mean(), 2)) + ' ± ' + str(round(single_2_QMDs.std(), 2))\n",
    "            final_table[col][5] = str(int(single_2_SRs.mean())) + ' ± ' + str(int(single_2_SRs.std()) )\n",
    "            final_table[col][6] = str(len(metrics['single_2_SR']))\n",
    "            col = \"MPRTP flow\"\n",
    "            final_table[col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "            final_table[col][1] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "            final_table[col][2] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "            final_table[col][3] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "            final_table[col][4] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "            final_table[col][5] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "            final_table[col][6] = str(len(metrics['SR']))\n",
    "        except:\n",
    "            print(\"Problem in calculations\", directory)\n",
    "\n",
    "        final_table = final_table.rename({\n",
    "            0: 'GP [kbps]',\n",
    "            1: 'ABU [%]', \n",
    "            2: 'LR [%]', \n",
    "            3: 'LRN',\n",
    "            4: 'QMD [ms]',\n",
    "            5: 'SR [kbps]',\n",
    "            6: 'Samples'}, axis='index')\n",
    "    #     display(final_table)\n",
    "        display(final_table.loc[['GP [kbps]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n",
    "    \n",
    "# We need the number of lost packets instead!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mprtp 10 - 3 paths, 2 mprtp 2 subflows\n",
    "# mprtp 11 - 2 path, 2 mprtp 2 subflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False, 'mp_channel': '1', 'mp_channel_2': '2', 'base_path': 'mprtp11'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:201: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:203: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:206: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:207: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPRTP Flows 1</th>\n",
       "      <th>MPRTP Flows 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Σ [kbps]</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>582 ± 162</td>\n",
       "      <td>612 ± 84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>0% ± 0%</td>\n",
       "      <td>0% ± 0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>102.13 ± 0.72</td>\n",
       "      <td>102.37 ± 0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MPRTP Flows 1  MPRTP Flows 2\n",
       "Σ [kbps]            2000           2000\n",
       "GP [kbps]      582 ± 162       612 ± 84\n",
       "LR [%]           0% ± 0%        0% ± 0%\n",
       "QMD [ms]   102.13 ± 0.72  102.37 ± 0.84"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#      shared bottleneck, fairness test - mprtp11\n",
    "#######################################################\n",
    "# TODO!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "packets_colnames = [\"Tracked NTP\",\n",
    "                    \"Sequence Number\",\n",
    "                    \"Timestamp\",\n",
    "                    \"SSRC\",\n",
    "                    \"Payload Type\",\n",
    "                    \"Payload Size\",\n",
    "                    \"Subflow ID\",\n",
    "                    \"Subflow Sequence Number\",\n",
    "                    \"Header Size\",\n",
    "                    \"Protect Begin\",\n",
    "                    \"Protect End\",\n",
    "                    \"Marker\",\n",
    "                   ]\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, channel, path, subflow_id, flow_id, path_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        # mprtpflow_1_flow_1_path_1_sr\n",
    "        sr = os.path.join(path, 'mprtpflow_' + str(channel) +\n",
    "                          '_flow_' + str(flow_id) + '_path_' + str(path_id) + '_sr.csv')\n",
    "        pathbw = os.path.join(path, 'path_' + str(path_id) + '_pathbw' + '.csv')\n",
    "        qmd = os.path.join(path, 'mprtpflow_' + str(channel) +\n",
    "                          '_flow_' + str(flow_id) + '_path_' + str(path_id) + '_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'mprtpflow_' + str(channel) +\n",
    "                          '_flow_' + str(flow_id) + '_path_' + str(path_id) + '_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "\n",
    "def collect_subflows(channel, path, subflows_num, flow_id, path_id):\n",
    "    subflows = [Subflow(channel, path, subflow_id, flow_id, path_id) for subflow_id in range(1, subflows_num + 1)]\n",
    "    return subflows\n",
    "\n",
    "    \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "configs = [\n",
    "{\n",
    "    'base_path': \"mprtp11\",\n",
    "    'debug': False,\n",
    "#     'debug': True,\n",
    "    'mp_channel': \"1\",\n",
    "    'mp_channel_2': \"2\",\n",
    "}, \n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    for path,dirs,files in os.walk(config['base_path']):\n",
    "        if len(dirs) < 1:\n",
    "            continue\n",
    "        final_table = pd.DataFrame()\n",
    "    #         print(\"number of subflows\", subflows_num)\n",
    "        suffix = \"_\" + str(subflows_num)\n",
    "        metrics = {\n",
    "            'SR': [],\n",
    "            'ABU': [],\n",
    "            'LR': [],\n",
    "            'LRN': [],            \n",
    "            'QMD': [],\n",
    "            'GP': [],\n",
    "\n",
    "            'SR_2': [],\n",
    "            'ABU_2': [],\n",
    "            'LR_2': [],\n",
    "            'LRN_2': [],            \n",
    "            'QMD_2': [],\n",
    "            'GP_2': [],\n",
    "        }\n",
    "\n",
    "        subjects = []\n",
    "        for directory in dirs:\n",
    "            subflows_num = 2\n",
    "            if not directory.endswith(suffix):\n",
    "                continue\n",
    "            try:\n",
    "                subflows = collect_subflows(config['mp_channel'], config['base_path'] + '/' + directory, subflows_num, \n",
    "                                            flow_id=1, path_id=1)\n",
    "                subflows_2 = collect_subflows(config['mp_channel_2'], config['base_path'] + '/' + directory, subflows_num, \n",
    "                                            flow_id=2, path_id=2)\n",
    "\n",
    "                SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "                ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) \n",
    "                LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "                LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "                QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "                GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "\n",
    "                SR_2 = sum(subflow.get_summary()['SR'] for subflow in subflows_2) \n",
    "                ABU_2 = sum(subflow.get_summary()['ABU'] for subflow in subflows_2) \n",
    "                LR_2 = sum(subflow.get_summary()['LR'] for subflow in subflows_2) / float(subflows_num)\n",
    "                LRN_2 = sum(subflow.get_summary()['LRN'] for subflow in subflows_2)           \n",
    "                QMD_2 = sum(subflow.get_summary()['QMD'] for subflow in subflows_2) / float(subflows_num)\n",
    "                GP_2 = sum(subflow.get_summary()['GP'] for subflow in subflows_2)\n",
    "                \n",
    "                metrics['SR'].append(SR)\n",
    "                metrics['ABU'].append(ABU)            \n",
    "                metrics['LR'].append(LR)\n",
    "                metrics['LRN'].append(LRN)            \n",
    "                metrics['QMD'].append(QMD)\n",
    "                metrics['GP'].append(GP)\n",
    "\n",
    "                metrics['SR_2'].append(SR_2)\n",
    "                metrics['ABU_2'].append(ABU_2)            \n",
    "                metrics['LR_2'].append(LR_2)\n",
    "                metrics['LRN_2'].append(LRN_2)            \n",
    "                metrics['QMD_2'].append(QMD_2)\n",
    "                metrics['GP_2'].append(GP_2)\n",
    "            except Exception, e:\n",
    "                print(\"There is an exception occured at:\", directory, \"Error message:\", e)\n",
    "                \n",
    "\n",
    "        # Display parameters\n",
    "        if config['debug']:\n",
    "            index = 1\n",
    "            if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                      it does not have the necessary minimum number of measurements\")\n",
    "#             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "            sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "            for item in sorted_list:\n",
    "                print(\"Rank:\", index)\n",
    "                print(\"Directory, ABU, LR, GP, QMD, LRN: \", item)\n",
    "                pdf = PDF(config['base_path'] + '/' + item[0] + '/' + config['base_path'] + '_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                display(pdf)\n",
    "                index += 1\n",
    "            print('-' * 20)\n",
    "\n",
    "        final_table[\"MPRTP Flows 1\"] = list(range(7))\n",
    "        final_table[\"MPRTP Flows 2\"] = list(range(7))        \n",
    "        SRs = np.asarray(metrics['SR'])\n",
    "        ABUs = np.asarray(metrics['ABU'])\n",
    "        LRs = np.asarray(metrics['LR'])\n",
    "        LRNs = np.asarray(metrics['LRN'])\n",
    "        QMDs = np.asarray(metrics['QMD'])\n",
    "        GPs = np.asarray(metrics['GP'])\n",
    "        \n",
    "        SRs_2 = np.asarray(metrics['SR_2'])\n",
    "        ABUs_2 = np.asarray(metrics['ABU_2'])\n",
    "        LRs_2 = np.asarray(metrics['LR_2'])\n",
    "        LRNs_2 = np.asarray(metrics['LRN_2'])\n",
    "        QMDs_2 = np.asarray(metrics['QMD_2'])\n",
    "        GPs_2 = np.asarray(metrics['GP_2'])\n",
    "        \n",
    "        try:\n",
    "            col = \"MPRTP Flows 1\"\n",
    "            final_table[col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "            final_table[col][1] = str(1000 * subflows_num)\n",
    "            final_table[col][2] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "            final_table[col][3] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "            final_table[col][4] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "            final_table[col][5] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "            final_table[col][6] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "            final_table[col][7] = str(len(metrics['SR']))\n",
    "            \n",
    "            col = \"MPRTP Flows 2\"\n",
    "            final_table[col][0] = str(int(GPs_2.mean())) + ' ± ' + str(int(GPs_2.std()))\n",
    "            final_table[col][1] = str(1000 * subflows_num)\n",
    "            final_table[col][2] = str(int(ABUs_2.mean() * 100)) + '% ± ' + str(int(ABUs_2.std() * 100) ) + '%'\n",
    "            final_table[col][3] = str(int(LRs_2.mean() * 100) ) + '% ± ' + str(int(LRs_2.std() * 100)) + '%'\n",
    "            final_table[col][4] = str(int(LRNs_2.mean())) + ' ± ' + str(int(LRNs_2.std()))        \n",
    "            final_table[col][5] = str(round(QMDs_2.mean(), 2)) + ' ± ' + str(round(QMDs_2.std(), 2))\n",
    "            final_table[col][6] = str(int(SRs_2.mean())) + ' ± ' + str(int(SRs_2.std()))\n",
    "            final_table[col][7] = str(len(metrics['SR_2']))\n",
    "        except:\n",
    "            print(\"Problem in calculations\", directory)\n",
    "\n",
    "        final_table = final_table.rename({\n",
    "            0: 'GP [kbps]',\n",
    "            1: 'Σ [kbps]', \n",
    "            2: 'ABU [%]',\n",
    "            3: 'LR [%]', \n",
    "            4: 'LRN',\n",
    "            5: 'QMD [ms]',\n",
    "            6: 'SR [kbps]',\n",
    "            7: 'Samples'}, axis='index')\n",
    "    #     display(final_table)\n",
    "        display(final_table.loc[['Σ [kbps]', 'GP [kbps]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n",
    "    \n",
    "# We need the number of lost packets instead!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': True, 'mp_channel': '1', 'mp_channel_2': '2', 'base_path': 'mprtp10'}\n",
      "for measuring ', subflows_num, 'subflows,                       it does not have the necessary minimum number of measurements\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:209: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:210: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:211: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:212: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:213: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:214: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPRTP Flows 1</th>\n",
       "      <th>MPRTP Flows 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Σ [kbps]</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>914 ± 144</td>\n",
       "      <td>995 ± 115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>1% ± 1%</td>\n",
       "      <td>2% ± 3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>112.7 ± 8.38</td>\n",
       "      <td>112.32 ± 8.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MPRTP Flows 1  MPRTP Flows 2\n",
       "Σ [kbps]           2000           2000\n",
       "GP [kbps]     914 ± 144      995 ± 115\n",
       "LR [%]          1% ± 1%        2% ± 3%\n",
       "QMD [ms]   112.7 ± 8.38  112.32 ± 8.51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#      shared bottleneck, fairness test - mprtp10\n",
    "#######################################################\n",
    "# TODO!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "packets_colnames = [\"Tracked NTP\",\n",
    "                    \"Sequence Number\",\n",
    "                    \"Timestamp\",\n",
    "                    \"SSRC\",\n",
    "                    \"Payload Type\",\n",
    "                    \"Payload Size\",\n",
    "                    \"Subflow ID\",\n",
    "                    \"Subflow Sequence Number\",\n",
    "                    \"Header Size\",\n",
    "                    \"Protect Begin\",\n",
    "                    \"Protect End\",\n",
    "                    \"Marker\",\n",
    "                   ]\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, channel, path, subflow_id, flow_id, path_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        # mprtpflow_1_flow_1_path_1_sr\n",
    "        sr = os.path.join(path, 'mprtpflow_' + str(channel) +\n",
    "                          '_flow_' + str(flow_id) + '_path_' + str(path_id) + '_sr.csv')\n",
    "        pathbw = os.path.join(path, 'path_' + str(path_id) + '_pathbw' + '.csv')\n",
    "        qmd = os.path.join(path, 'mprtpflow_' + str(channel) +\n",
    "                          '_flow_' + str(flow_id) + '_path_' + str(path_id) + '_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'mprtpflow_' + str(channel) +\n",
    "                          '_flow_' + str(flow_id) + '_path_' + str(path_id) + '_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "\n",
    "def collect_subflows(channel, path, subflows_num, flow_ids, path_ids):\n",
    "    subflows = []\n",
    "    subflow_id = 0\n",
    "    for path_id in path_ids:\n",
    "        flow_id = flow_ids[subflow_id]\n",
    "        subflow_id += 1\n",
    "        subflow = Subflow(channel, path, subflow_id, flow_id, path_id)\n",
    "        subflows.append(subflow)\n",
    "    return subflows\n",
    "\n",
    "    \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "configs = [\n",
    "{\n",
    "    'base_path': \"mprtp10\",\n",
    "#     'debug': False,\n",
    "    'debug': True,\n",
    "    'mp_channel': \"1\",\n",
    "    'mp_channel_2': \"2\",\n",
    "}, \n",
    "]\n",
    "subflows_num = 2\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    for path,dirs,files in os.walk(config['base_path']):\n",
    "        if len(dirs) < 1:\n",
    "            continue\n",
    "        final_table = pd.DataFrame()\n",
    "    #         print(\"number of subflows\", subflows_num)\n",
    "        suffix = \"_\" + str(subflows_num)\n",
    "        metrics = {\n",
    "            'SR': [],\n",
    "            'ABU': [],\n",
    "            'LR': [],\n",
    "            'LRN': [],            \n",
    "            'QMD': [],\n",
    "            'GP': [],\n",
    "\n",
    "            'SR_2': [],\n",
    "            'ABU_2': [],\n",
    "            'LR_2': [],\n",
    "            'LRN_2': [],            \n",
    "            'QMD_2': [],\n",
    "            'GP_2': [],\n",
    "        }\n",
    "\n",
    "        subjects = []\n",
    "        for directory in dirs:\n",
    "            subflows_num = 2\n",
    "            if not directory.endswith(suffix):\n",
    "                continue\n",
    "            try:\n",
    "                subflows = collect_subflows(config['mp_channel'], config['base_path'] + '/' + directory, subflows_num, \n",
    "                                            flow_ids=[1,2], path_ids=[1,2])\n",
    "                subflows_2 = collect_subflows(config['mp_channel_2'], config['base_path'] + '/' + directory, subflows_num, \n",
    "                                            flow_ids=[1,2], path_ids=[2,3])\n",
    "\n",
    "                SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "                ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) \n",
    "                LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "                LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "                QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "                GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "\n",
    "                SR_2 = sum(subflow.get_summary()['SR'] for subflow in subflows_2) \n",
    "                ABU_2 = sum(subflow.get_summary()['ABU'] for subflow in subflows_2) \n",
    "                LR_2 = sum(subflow.get_summary()['LR'] for subflow in subflows_2) / float(subflows_num)\n",
    "                LRN_2 = sum(subflow.get_summary()['LRN'] for subflow in subflows_2)           \n",
    "                QMD_2 = sum(subflow.get_summary()['QMD'] for subflow in subflows_2) / float(subflows_num)\n",
    "                GP_2 = sum(subflow.get_summary()['GP'] for subflow in subflows_2)\n",
    "                \n",
    "                metrics['SR'].append(SR)\n",
    "                metrics['ABU'].append(ABU)            \n",
    "                metrics['LR'].append(LR)\n",
    "                metrics['LRN'].append(LRN)            \n",
    "                metrics['QMD'].append(QMD)\n",
    "                metrics['GP'].append(GP)\n",
    "\n",
    "                metrics['SR_2'].append(SR_2)\n",
    "                metrics['ABU_2'].append(ABU_2)            \n",
    "                metrics['LR_2'].append(LR_2)\n",
    "                metrics['LRN_2'].append(LRN_2)            \n",
    "                metrics['QMD_2'].append(QMD_2)\n",
    "                metrics['GP_2'].append(GP_2)\n",
    "            except Exception, e:\n",
    "                print(\"There is an exception occured at:\", directory, \"Error message:\", e)\n",
    "                \n",
    "\n",
    "        # Display parameters\n",
    "        if config['debug']:\n",
    "            index = 1\n",
    "            if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                      it does not have the necessary minimum number of measurements\")\n",
    "#             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "            sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "            for item in sorted_list:\n",
    "                print(\"Rank:\", index)\n",
    "                print(\"Directory, ABU, LR, GP, QMD, LRN: \", item)\n",
    "                pdf = PDF(config['base_path'] + '/' + item[0] + '/' + config['base_path'] + '_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                display(pdf)\n",
    "                index += 1\n",
    "            print('-' * 20)\n",
    "\n",
    "        final_table[\"MPRTP Flows 1\"] = list(range(7))\n",
    "        final_table[\"MPRTP Flows 2\"] = list(range(7))        \n",
    "        SRs = np.asarray(metrics['SR'])\n",
    "        ABUs = np.asarray(metrics['ABU'])\n",
    "        LRs = np.asarray(metrics['LR'])\n",
    "        LRNs = np.asarray(metrics['LRN'])\n",
    "        QMDs = np.asarray(metrics['QMD'])\n",
    "        GPs = np.asarray(metrics['GP'])\n",
    "        \n",
    "        SRs_2 = np.asarray(metrics['SR_2'])\n",
    "        ABUs_2 = np.asarray(metrics['ABU_2'])\n",
    "        LRs_2 = np.asarray(metrics['LR_2'])\n",
    "        LRNs_2 = np.asarray(metrics['LRN_2'])\n",
    "        QMDs_2 = np.asarray(metrics['QMD_2'])\n",
    "        GPs_2 = np.asarray(metrics['GP_2'])\n",
    "        \n",
    "        try:\n",
    "            col = \"MPRTP Flows 1\"\n",
    "            final_table[col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "            final_table[col][1] = str(1000 * subflows_num)\n",
    "            final_table[col][2] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "            final_table[col][3] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "            final_table[col][4] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "            final_table[col][5] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "            final_table[col][6] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "            final_table[col][7] = str(len(metrics['SR']))\n",
    "            \n",
    "            col = \"MPRTP Flows 2\"\n",
    "            final_table[col][0] = str(int(GPs_2.mean())) + ' ± ' + str(int(GPs_2.std()))\n",
    "            final_table[col][1] = str(1000 * subflows_num)\n",
    "            final_table[col][2] = str(int(ABUs_2.mean() * 100)) + '% ± ' + str(int(ABUs_2.std() * 100) ) + '%'\n",
    "            final_table[col][3] = str(int(LRs_2.mean() * 100) ) + '% ± ' + str(int(LRs_2.std() * 100)) + '%'\n",
    "            final_table[col][4] = str(int(LRNs_2.mean())) + ' ± ' + str(int(LRNs_2.std()))        \n",
    "            final_table[col][5] = str(round(QMDs_2.mean(), 2)) + ' ± ' + str(round(QMDs_2.std(), 2))\n",
    "            final_table[col][6] = str(int(SRs_2.mean())) + ' ± ' + str(int(SRs_2.std()))\n",
    "            final_table[col][7] = str(len(metrics['SR_2']))\n",
    "        except:\n",
    "            print(\"Problem in calculations\", directory)\n",
    "\n",
    "        final_table = final_table.rename({\n",
    "            0: 'GP [kbps]',\n",
    "            1: 'Σ [kbps]',\n",
    "            2: 'ABU [%]', \n",
    "            3: 'LR [%]', \n",
    "            4: 'LRN',\n",
    "            5: 'QMD [ms]',\n",
    "            6: 'SR [kbps]',\n",
    "            7: 'Samples'}, axis='index')\n",
    "    #     display(final_table)\n",
    "        display(final_table.loc[['Σ [kbps]', 'GP [kbps]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n",
    "    \n",
    "# We need the number of lost packets instead!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
