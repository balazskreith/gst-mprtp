{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#                 constants for the evaluators\n",
    "#######################################################\n",
    "\n",
    "MIN_MEASUREMENT_NUMBER = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False, 'channel': '1', 'base_path': 'mprtp2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Subflow</th>\n",
       "      <th>2 Subflows</th>\n",
       "      <th>3 Subflows</th>\n",
       "      <th>5 Subflows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>481 ± 42</td>\n",
       "      <td>724 ± 88</td>\n",
       "      <td>1149 ± 81</td>\n",
       "      <td>1791 ± 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>1% ± 0%</td>\n",
       "      <td>2% ± 0%</td>\n",
       "      <td>2% ± 0%</td>\n",
       "      <td>2% ± 0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>135.25 ± 2.72</td>\n",
       "      <td>110.67 ± 1.5</td>\n",
       "      <td>109.92 ± 1.95</td>\n",
       "      <td>109.23 ± 2.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1 Subflow    2 Subflows     3 Subflows     5 Subflows\n",
       "GP [kbps]       481 ± 42      724 ± 88      1149 ± 81     1791 ± 255\n",
       "LR [%]           1% ± 0%       2% ± 0%        2% ± 0%        2% ± 0%\n",
       "QMD [ms]   135.25 ± 2.72  110.67 ± 1.5  109.92 ± 1.95  109.23 ± 2.64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'debug': False, 'channel': '1', 'base_path': 'mprtp5'}\n",
      "('There is an exception occured at:', 'FRACTaL_Y5VF95_0_50ms_0ms_1')\n",
      "('There is an exception occured at:', 'FRACTaL_Y5VF95_2_50ms_0ms_1')\n",
      "('There is an exception occured at:', 'FRACTaL_Y5VF95_1_50ms_0ms_1')\n",
      "('There is an exception occured at:', 'FRACTaL_Y5VF95_4_50ms_0ms_1')\n",
      "('There is an exception occured at:', 'FRACTaL_N72ZV0_1_50ms_0ms_2')\n",
      "('There is an exception occured at:', 'FRACTaL_N72ZV0_4_50ms_0ms_2')\n",
      "('There is an exception occured at:', 'FRACTaL_N72ZV0_3_50ms_0ms_2')\n",
      "('There is an exception occured at:', 'FRACTaL_N72ZV0_0_50ms_0ms_2')\n",
      "('There is an exception occured at:', 'FRACTaL_N72ZV0_2_50ms_0ms_2')\n",
      "('There is an exception occured at:', 'FRACTaL_VQ4FLD_0_50ms_0ms_3')\n",
      "('There is an exception occured at:', 'FRACTaL_VQ4FLD_3_50ms_0ms_3')\n",
      "('There is an exception occured at:', 'FRACTaL_VQ4FLD_1_50ms_0ms_3')\n",
      "('There is an exception occured at:', 'FRACTaL_VQ4FLD_4_50ms_0ms_3')\n",
      "('There is an exception occured at:', 'FRACTaL_W219HC_2_50ms_0ms_5')\n",
      "('There is an exception occured at:', 'FRACTaL_W219HC_0_50ms_0ms_5')\n",
      "('There is an exception occured at:', 'FRACTaL_W219HC_3_50ms_0ms_5')\n",
      "('There is an exception occured at:', 'FRACTaL_W219HC_4_50ms_0ms_5')\n",
      "('There is an exception occured at:', 'FRACTaL_W219HC_1_50ms_0ms_5')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Subflow</th>\n",
       "      <th>2 Subflows</th>\n",
       "      <th>3 Subflows</th>\n",
       "      <th>5 Subflows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>1780 ± 0</td>\n",
       "      <td>1780 ± 0</td>\n",
       "      <td>1780 ± 0</td>\n",
       "      <td>1780 ± 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>14% ± 0%</td>\n",
       "      <td>7% ± 0%</td>\n",
       "      <td>4% ± 0%</td>\n",
       "      <td>2% ± 0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>540.69 ± 0.0</td>\n",
       "      <td>270.34 ± 0.0</td>\n",
       "      <td>180.23 ± 0.0</td>\n",
       "      <td>108.14 ± 0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1 Subflow    2 Subflows    3 Subflows    5 Subflows\n",
       "GP [kbps]      1780 ± 0      1780 ± 0      1780 ± 0      1780 ± 0\n",
       "LR [%]         14% ± 0%       7% ± 0%       4% ± 0%       2% ± 0%\n",
       "QMD [ms]   540.69 ± 0.0  270.34 ± 0.0  180.23 ± 0.0  108.14 ± 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#                 in-phase evaluator - mprtp2\n",
    "#######################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "packets_colnames = [\"Tracked NTP\",\n",
    "                    \"Sequence Number\",\n",
    "                    \"Timestamp\",\n",
    "                    \"SSRC\",\n",
    "                    \"Payload Type\",\n",
    "                    \"Payload Size\",\n",
    "                    \"Subflow ID\",\n",
    "                    \"Subflow Sequence Number\",\n",
    "                    \"Header Size\",\n",
    "                    \"Protect Begin\",\n",
    "                    \"Protect End\",\n",
    "                    \"Marker\",\n",
    "                   ]\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, channel, path, subflow_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        sr = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'subflow_'+ str(subflow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "        \n",
    "    \n",
    "def collect_subflows(channel, path, subflows_num):\n",
    "    subflows = [Subflow(channel, path, subflow_id) for subflow_id in range(1, subflows_num + 1)]\n",
    "    return subflows\n",
    "\n",
    "    \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "configs = [\n",
    "{\n",
    "    'base_path': \"mprtp2\",\n",
    "    'debug': False,\n",
    "#     'debug': True,\n",
    "    'channel': \"1\"\n",
    "},\n",
    "{\n",
    "    'base_path': \"mprtp5\",\n",
    "    'debug': False,\n",
    "#     'debug': True,\n",
    "    'channel': \"1\"\n",
    "}, \n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    for path,dirs,files in os.walk(base_path):\n",
    "        if len(dirs) < 1:\n",
    "            continue\n",
    "        final_table = pd.DataFrame()\n",
    "    #     for subflows_num in [5]:\n",
    "        for subflows_num in [1, 2, 3, 5]:\n",
    "    #         print(\"number of subflows\", subflows_num)\n",
    "            suffix = \"_\" + str(subflows_num)\n",
    "            metrics = {\n",
    "                'SR': [],\n",
    "                'ABU': [],\n",
    "                'LR': [],\n",
    "                'LRN': [],            \n",
    "                'QMD': [],\n",
    "                'GP': [],\n",
    "            }\n",
    "            subjects = []\n",
    "            for directory in dirs:\n",
    "                if not directory.endswith(suffix):\n",
    "                    continue\n",
    "                try:\n",
    "                    subflows = collect_subflows(config['channel'], config['base_path'] + '/' + directory, subflows_num)\n",
    "                except:\n",
    "                    print(\"There is an exception occured at:\", directory)\n",
    "\n",
    "                abs_ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows)\n",
    "                abs_LR = sum(subflow.get_summary()['LR'] for subflow in subflows)\n",
    "                abs_GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "                abs_QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows)\n",
    "                abs_LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)\n",
    "                subjects.append((directory, abs_ABU, abs_LR, abs_GP, abs_QMD, abs_LRN))\n",
    "\n",
    "                SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "                ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) / float(subflows_num)\n",
    "                LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "                LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "                QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "                GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "                metrics['SR'].append(SR)\n",
    "                metrics['ABU'].append(ABU)            \n",
    "                metrics['LR'].append(LR)\n",
    "                metrics['LRN'].append(LRN)            \n",
    "                metrics['QMD'].append(QMD)\n",
    "                metrics['GP'].append(GP)\n",
    "\n",
    "            # Selection method\n",
    "            # setup sets for the max 10 based on criteria (LR, ABU, and verifications) and filter out the \n",
    "            # intersection of the weakers\n",
    "\n",
    "            # Display parameters\n",
    "            if config['debug']:\n",
    "                index = 1\n",
    "                if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                    print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                          it does not have the necessary minimum number of measurements\")\n",
    "    #             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "                sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "                for item in sorted_list:\n",
    "                    print(\"Rank:\", index)\n",
    "                    print(\"Directory, ABU, LR, GP, QMD, LRN: \", item)\n",
    "                    pdf = PDF(base_path + '/' + item[0] + '/' + 'mprtp2_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                    display(pdf)\n",
    "                    index += 1\n",
    "                print('-' * 20)\n",
    "\n",
    "            subflow_col = (str(subflows_num) + ' Subflows') if 1 < subflows_num else '1 Subflow'\n",
    "            final_table[subflow_col] = list(range(7))\n",
    "            SRs = np.asarray(metrics['SR'])\n",
    "            ABUs = np.asarray(metrics['ABU'])\n",
    "            LRs = np.asarray(metrics['LR'])\n",
    "            LRNs = np.asarray(metrics['LRN'])\n",
    "            QMDs = np.asarray(metrics['QMD'])\n",
    "            GPs = np.asarray(metrics['GP'])\n",
    "\n",
    "            final_table[subflow_col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "            final_table[subflow_col][1] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "            final_table[subflow_col][2] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "            final_table[subflow_col][3] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "            final_table[subflow_col][4] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "            final_table[subflow_col][5] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "            final_table[subflow_col][6] = str(len(metrics['SR']))\n",
    "\n",
    "        final_table = final_table.rename({\n",
    "            0: 'GP [kbps]',\n",
    "            1: 'ABU [%]', \n",
    "            2: 'LR [%]', \n",
    "            3: 'LRN',\n",
    "            4: 'QMD [ms]',\n",
    "            5: 'SR [kbps]',\n",
    "            6: 'Samples'}, axis='index')\n",
    "    #     display(final_table)\n",
    "        display(final_table.loc[['GP [kbps]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n",
    "    \n",
    "# We need the number of lost packets instead!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:173: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 Subflow</th>\n",
       "      <th>2 Subflows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GP [kbps]</th>\n",
       "      <td>1002 ± 88</td>\n",
       "      <td>1844 ± 96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TE [%]</th>\n",
       "      <td>6% ± 0%</td>\n",
       "      <td>4% ± 1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR [%]</th>\n",
       "      <td>0% ± 0%</td>\n",
       "      <td>1% ± 0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QMD [ms]</th>\n",
       "      <td>114.73 ± 2.2</td>\n",
       "      <td>107.43 ± 2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1 Subflow    2 Subflows\n",
       "GP [kbps]     1002 ± 88     1844 ± 96\n",
       "TE [%]          6% ± 0%       4% ± 1%\n",
       "LR [%]          0% ± 0%       1% ± 0%\n",
       "QMD [ms]   114.73 ± 2.2  107.43 ± 2.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################################\n",
    "#                 out-of-phase evaluator - mprtp4\n",
    "#######################################################\n",
    "\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def extract_dataframe(filename, identifier):\n",
    "    header = False\n",
    "    content = []\n",
    "    identifier_length = len(identifier)\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if identifier not in line:\n",
    "                continue\n",
    "            stat_line = line[identifier_length:]\n",
    "            if \"Subflow ID\" in stat_line:\n",
    "                if header is True:\n",
    "                    continue\n",
    "                header = True\n",
    "            content.append(stat_line)\n",
    "    if len(content) < 1:\n",
    "        return None\n",
    "    TESTDATA = StringIO('\\n'.join(map(unicode,content)))\n",
    "    return pd.read_csv(TESTDATA)\n",
    "\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, path, stats_df, subflow_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._stat = stats_df[stats_df[\"Subflow ID\"] == subflow_id]\n",
    "\n",
    "        sr = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'subflow_'+ str(subflow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_1_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_1_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp,\n",
    "            'TE': self._stat[\"Target Error\"].mean()\n",
    "        }\n",
    "\n",
    "# The variance around the target is not significantly higher than in case of one subflow\n",
    "# the ratio stability\n",
    "\n",
    "base_path = \"mprtp4\"\n",
    "debug = False\n",
    "# debug = True\n",
    "for path,dirs,files in os.walk(base_path):\n",
    "    if len(dirs) < 1:\n",
    "        continue\n",
    "    final_table = pd.DataFrame()\n",
    "#     for subflows_num in [1]:\n",
    "    for subflows_num in [1, 2]:\n",
    "        suffix = \"_\" + str(subflows_num)\n",
    "        metrics = {\n",
    "            'SR': [],\n",
    "            'ABU': [],\n",
    "            'LR': [],\n",
    "            'LRN': [],            \n",
    "            'QMD': [],\n",
    "            'GP': [],\n",
    "            'TE': [],\n",
    "        }\n",
    "        subjects = []\n",
    "        for directory in dirs:\n",
    "            if not directory.endswith(suffix):\n",
    "                continue\n",
    "            filename = os.path.join(base_path, directory, \"mprtpflow_4_\" + str(subflows_num) + \"-snd.log\")\n",
    "            stats_df = extract_dataframe(filename, \"Stat:\")\n",
    "            stats_df[\"Target Error\"] = (stats_df[\"Target Rate [kbps]\"] - stats_df[\"Sending Rate [kbps]\"]) / stats_df[\"Target Rate [kbps]\"]\n",
    "            subflows = []\n",
    "            for subflow_id in range(1, subflows_num + 1):\n",
    "                subflows.append(Subflow(os.path.join(base_path, directory), stats_df, subflow_id))\n",
    "            \n",
    "            abs_ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows)\n",
    "            abs_LR = sum(subflow.get_summary()['LR'] for subflow in subflows)\n",
    "            abs_GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "            abs_QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows)\n",
    "            abs_TE = sum(subflow.get_summary()['TE'] for subflow in subflows)\n",
    "            subjects.append((directory, abs_ABU, abs_LR, abs_GP, abs_QMD, abs_TE))\n",
    "            \n",
    "            SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "            ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) / float(subflows_num)\n",
    "            LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "            LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "            QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "            GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "            TE = sum(subflow.get_summary()['TE'] for subflow in subflows) / float(subflows_num)            \n",
    "            metrics['SR'].append(SR)\n",
    "            metrics['ABU'].append(ABU)            \n",
    "            metrics['LR'].append(LR)\n",
    "            metrics['LRN'].append(LRN)            \n",
    "            metrics['QMD'].append(QMD)\n",
    "            metrics['GP'].append(GP)\n",
    "            metrics['TE'].append(TE)\n",
    "        \n",
    "        # Display parameters\n",
    "        if debug:\n",
    "            index = 1\n",
    "            if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                      it does not have the necessary minimum number of measurements\")\n",
    "#             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "            sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "            for item in sorted_list:\n",
    "                print(\"Rank:\", index)\n",
    "                print(\"Directory, ABU, LR, GP, QMD, TE: \", item)\n",
    "                pdf = PDF(base_path + '/' + item[0] + '/' + 'mprtp4_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                display(pdf)\n",
    "                index += 1\n",
    "            print('-' * 20)\n",
    "            \n",
    "        subflow_col = (str(subflows_num) + ' Subflows') if 1 < subflows_num else '1 Subflow'\n",
    "        final_table[subflow_col] = list(range(7))\n",
    "        SRs = np.asarray(metrics['SR'])\n",
    "        ABUs = np.asarray(metrics['ABU'])\n",
    "        LRs = np.asarray(metrics['LR'])\n",
    "        LRNs = np.asarray(metrics['LRN'])\n",
    "        QMDs = np.asarray(metrics['QMD'])\n",
    "        GPs = np.asarray(metrics['GP'])\n",
    "        TEs = np.asarray(metrics['TE'])\n",
    "\n",
    "        final_table[subflow_col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "        final_table[subflow_col][1] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "        final_table[subflow_col][2] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "        final_table[subflow_col][3] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "        final_table[subflow_col][4] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "        final_table[subflow_col][5] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "        final_table[subflow_col][6] = str(int(TEs.mean() * 100)) + '% ± ' + str(int(TEs.std() * 100) ) + '%'\n",
    "        final_table[subflow_col][7] = str(len(metrics['SR']))\n",
    "        \n",
    "    final_table = final_table.rename({\n",
    "        0: 'GP [kbps]',\n",
    "        1: 'ABU [%]', \n",
    "        2: 'LR [%]', \n",
    "        3: 'LRN',\n",
    "        4: 'QMD [ms]',\n",
    "        5: 'SR [kbps]',\n",
    "        6: 'TE [%]',\n",
    "        7: 'Samples'}, axis='index')\n",
    "#     display(final_table)\n",
    "    display(final_table.loc[['GP [kbps]', 'TE [%]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#      shared bottleneck, fairness test - mprtp5\n",
    "#######################################################\n",
    "# TODO!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class PDF(object):\n",
    "    def __init__(self, pdf, size=(400,200)):\n",
    "        self.pdf = pdf\n",
    "        self.size = size\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        return '<iframe src={0} width={1[0]} height={1[1]}></iframe>'.format(self.pdf, self.size)\n",
    "\n",
    "    def _repr_latex_(self):\n",
    "        return r'\\includegraphics[width=1.0\\textwidth]{{{0}}}'.format(self.pdf)\n",
    "\n",
    "packets_colnames = [\"Tracked NTP\",\n",
    "                    \"Sequence Number\",\n",
    "                    \"Timestamp\",\n",
    "                    \"SSRC\",\n",
    "                    \"Payload Type\",\n",
    "                    \"Payload Size\",\n",
    "                    \"Subflow ID\",\n",
    "                    \"Subflow Sequence Number\",\n",
    "                    \"Header Size\",\n",
    "                    \"Protect Begin\",\n",
    "                    \"Protect End\",\n",
    "                    \"Marker\",\n",
    "                   ]\n",
    "\n",
    "class Subflow:\n",
    "    def __init__(self, channel, path, subflow_id):\n",
    "        self._path = path\n",
    "        self._subflow_id = subflow_id\n",
    "        self._df = pd.DataFrame()\n",
    "        sr = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_sr.csv')\n",
    "        pathbw = os.path.join(path, 'subflow_'+ str(subflow_id) +'_pathbw.csv')\n",
    "        qmd = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_qmd.csv')\n",
    "        self._df = pd.concat([\n",
    "            pd.read_csv(sr, index_col=None, header=None, names=['Sending Rate', 'FEC Rate']),\n",
    "            pd.read_csv(pathbw, index_col=None, header=None, names=['Capacity']),\n",
    "            pd.read_csv(qmd, index_col=None, header=None, names=['Queue Delay']),\n",
    "        ], axis=1)\n",
    "\n",
    "        snd_csv = os.path.join(path, 'snd_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        snd_packets = pd.read_csv(snd_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        snd_packets = snd_packets[snd_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        ply_csv = os.path.join(path, 'rcv_packets_' + channel + '_s'+ str(subflow_id) +'.csv')\n",
    "        ply_packets = pd.read_csv(ply_csv, index_col=None, header=None, names=packets_colnames)\n",
    "        ply_packets = ply_packets[ply_packets[\"Payload Type\"] == 96]\n",
    "        \n",
    "        self._df['SR'] = self._df.apply (lambda row: (row['Sending Rate'] + row['FEC Rate']) // 125, axis=1)\n",
    "        self._df['ABU'] = self._df.apply (lambda row: ((row['Sending Rate'] + row['FEC Rate']) // 125) / row['Capacity'], axis=1)        \n",
    "        self._df['QMD'] = self._df.apply (lambda row: row['Queue Delay'] // 1000, axis=1)\n",
    "        self._lr = 1.0 - float(len(ply_packets)) / float(len(snd_packets))\n",
    "        self._lrn = len(snd_packets) - len(ply_packets)\n",
    "        gp = os.path.join(path, 'rtpsubflow_'+ str(subflow_id) +'_gp_avg.csv')\n",
    "        with open(gp, 'r') as content_file:\n",
    "            self._gp = float(content_file.read()) / 125\n",
    "        \n",
    "    @property\n",
    "    def sr(self):\n",
    "        return self._sr\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            'SR': self._df['SR'].mean(),\n",
    "            'ABU': self._df[\"ABU\"].mean(),\n",
    "            'QMD': self._df['QMD'].mean(),\n",
    "            'LR': self._lr,\n",
    "            'LRN': self._lrn,            \n",
    "            'GP': self._gp\n",
    "        }\n",
    "        \n",
    "    \n",
    "def collect_subflows(channel, path, subflows_num):\n",
    "    subflows = [Subflow(channel, path, subflow_id) for subflow_id in range(1, subflows_num + 1)]\n",
    "    return subflows\n",
    "\n",
    "    \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "configs = [\n",
    "{\n",
    "    'base_path': \"mprtp5\",\n",
    "    'debug': False,\n",
    "#     'debug': True,\n",
    "    'channel': \"2\"\n",
    "}, \n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    print(config)\n",
    "    for path,dirs,files in os.walk(base_path):\n",
    "        if len(dirs) < 1:\n",
    "            continue\n",
    "        final_table = pd.DataFrame()\n",
    "    #     for subflows_num in [5]:\n",
    "        for subflows_num in [1, 2, 3, 5]:\n",
    "    #         print(\"number of subflows\", subflows_num)\n",
    "            suffix = \"_\" + str(subflows_num)\n",
    "            metrics = {\n",
    "                'SR': [],\n",
    "                'ABU': [],\n",
    "                'LR': [],\n",
    "                'LRN': [],            \n",
    "                'QMD': [],\n",
    "                'GP': [],\n",
    "            }\n",
    "            subjects = []\n",
    "            for directory in dirs:\n",
    "                if not directory.endswith(suffix):\n",
    "                    continue\n",
    "                try:\n",
    "                    subflows = collect_subflows(config['channel'], config['base_path'] + '/' + directory, subflows_num)\n",
    "                except:\n",
    "                    print(\"There is an exception occured at:\", directory)\n",
    "\n",
    "                abs_ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows)\n",
    "                abs_LR = sum(subflow.get_summary()['LR'] for subflow in subflows)\n",
    "                abs_GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "                abs_QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows)\n",
    "                abs_LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)\n",
    "                subjects.append((directory, abs_ABU, abs_LR, abs_GP, abs_QMD, abs_LRN))\n",
    "\n",
    "                SR = sum(subflow.get_summary()['SR'] for subflow in subflows) \n",
    "                ABU = sum(subflow.get_summary()['ABU'] for subflow in subflows) / float(subflows_num)\n",
    "                LR = sum(subflow.get_summary()['LR'] for subflow in subflows) / float(subflows_num)\n",
    "                LRN = sum(subflow.get_summary()['LRN'] for subflow in subflows)           \n",
    "                QMD = sum(subflow.get_summary()['QMD'] for subflow in subflows) / float(subflows_num)\n",
    "                GP = sum(subflow.get_summary()['GP'] for subflow in subflows)\n",
    "                metrics['SR'].append(SR)\n",
    "                metrics['ABU'].append(ABU)            \n",
    "                metrics['LR'].append(LR)\n",
    "                metrics['LRN'].append(LRN)            \n",
    "                metrics['QMD'].append(QMD)\n",
    "                metrics['GP'].append(GP)\n",
    "\n",
    "            # Display parameters\n",
    "            if config['debug']:\n",
    "                index = 1\n",
    "                if (len(subjects) < MIN_MEASUREMENT_NUMBER):\n",
    "                    print(\"for measuring ', subflows_num, 'subflows, \\\n",
    "                          it does not have the necessary minimum number of measurements\")\n",
    "    #             sorted_list = sorted(subjects, key=lambda x: x[1], reverse=True)\n",
    "                sorted_list = sorted(subjects, key=lambda x: x[4], reverse=False)\n",
    "                for item in sorted_list:\n",
    "                    print(\"Rank:\", index)\n",
    "                    print(\"Directory, ABU, LR, GP, QMD, LRN: \", item)\n",
    "                    pdf = PDF(base_path + '/' + item[0] + '/' + 'mprtp2_aggr_FRACTaL_50ms_0ms.pdf')\n",
    "                    display(pdf)\n",
    "                    index += 1\n",
    "                print('-' * 20)\n",
    "\n",
    "            subflow_col = (str(subflows_num) + ' Subflows') if 1 < subflows_num else '1 Subflow'\n",
    "            final_table[subflow_col] = list(range(7))\n",
    "            SRs = np.asarray(metrics['SR'])\n",
    "            ABUs = np.asarray(metrics['ABU'])\n",
    "            LRs = np.asarray(metrics['LR'])\n",
    "            LRNs = np.asarray(metrics['LRN'])\n",
    "            QMDs = np.asarray(metrics['QMD'])\n",
    "            GPs = np.asarray(metrics['GP'])\n",
    "\n",
    "            final_table[subflow_col][0] = str(int(GPs.mean())) + ' ± ' + str(int(GPs.std()))\n",
    "            final_table[subflow_col][1] = str(int(ABUs.mean() * 100)) + '% ± ' + str(int(ABUs.std() * 100) ) + '%'\n",
    "            final_table[subflow_col][2] = str(int(LRs.mean() * 100) ) + '% ± ' + str(int(LRs.std() * 100)) + '%'\n",
    "            final_table[subflow_col][3] = str(int(LRNs.mean())) + ' ± ' + str(int(LRNs.std()))        \n",
    "            final_table[subflow_col][4] = str(round(QMDs.mean(), 2)) + ' ± ' + str(round(QMDs.std(), 2))\n",
    "            final_table[subflow_col][5] = str(int(SRs.mean())) + ' ± ' + str(int(SRs.std()) )\n",
    "            final_table[subflow_col][6] = str(len(metrics['SR']))\n",
    "\n",
    "        final_table = final_table.rename({\n",
    "            0: 'GP [kbps]',\n",
    "            1: 'ABU [%]', \n",
    "            2: 'LR [%]', \n",
    "            3: 'LRN',\n",
    "            4: 'QMD [ms]',\n",
    "            5: 'SR [kbps]',\n",
    "            6: 'Samples'}, axis='index')\n",
    "    #     display(final_table)\n",
    "        display(final_table.loc[['GP [kbps]', 'LR [%]', 'QMD [ms]'], :])\n",
    "\n",
    "    \n",
    "# We need the number of lost packets instead!!!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
